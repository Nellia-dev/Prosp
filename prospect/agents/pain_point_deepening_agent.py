from typing import Optional, List
from pydantic import BaseModel, Field

from agents.base_agent import BaseAgent
from core_logic.llm_client import LLMClientBase

# Constants
GEMINI_TEXT_INPUT_TRUNCATE_CHARS = 180000

class PainPointDeepeningInput(BaseModel):
    lead_analysis: str
    persona_profile: str
    product_service_offered: str
    company_name: str # Added company_name for more context

class DetailedPainPoint(BaseModel):
    pain_description: str
    business_impact: str
    solution_alignment: str # How the user's product/service aligns

class PainPointDeepeningOutput(BaseModel):
    primary_pain_category: str = "N√£o especificado"
    detailed_pain_points: List[DetailedPainPoint] = Field(default_factory=list)
    urgency_level: str = "medium" # e.g., low, medium, high, critical
    investigative_questions: List[str] = Field(default_factory=list)
    error_message: Optional[str] = None

class PainPointDeepeningAgent(BaseAgent[PainPointDeepeningInput, PainPointDeepeningOutput]):
    def __init__(self, name: str, description: str, llm_client: LLMClientBase, **kwargs):
        super().__init__(name=name, description=description, llm_client=llm_client, **kwargs)

    def _truncate_text(self, text: str, max_chars: int) -> str:
        """Truncates text to a maximum number of characters."""
        return text[:max_chars]

    def process(self, input_data: PainPointDeepeningInput) -> PainPointDeepeningOutput:
        deepened_pain_points = ""
        error_message = None
        
        self.logger.info(f"üéØ PAIN POINT DEEPENING STARTING for company: {input_data.company_name}")
        self.logger.info(f"üìä Input data: analysis_length={len(input_data.lead_analysis)}, persona_length={len(input_data.persona_profile)}")
        self.logger.debug(f"üîß Service offered: {input_data.product_service_offered}")

        try:
            # Truncate inputs
            truncated_analysis = self._truncate_text(input_data.lead_analysis, GEMINI_TEXT_INPUT_TRUNCATE_CHARS // 4)
            truncated_persona = self._truncate_text(input_data.persona_profile, GEMINI_TEXT_INPUT_TRUNCATE_CHARS // 4)
            
            self.logger.debug(f"‚úÇÔ∏è  Text truncation: analysis {len(input_data.lead_analysis)} -> {len(truncated_analysis)}, persona {len(input_data.persona_profile)} -> {len(truncated_persona)}")
            
            prompt_template = """
                Voc√™ √© um Consultor de Vendas Estrat√©gicas especializado em identificar e aprofundar os pontos de dor de clientes B2B.
                Seu objetivo √© ajudar a equipe de vendas a entender melhor as necessidades impl√≠citas e expl√≠citas da persona na empresa '{company_name}'.

                AN√ÅLISE DO LEAD:
                {lead_analysis}

                PERFIL DA PERSONA (Tomador de Decis√£o na {company_name}):
                {persona_profile}

                PRODUTO/SERVI√áO QUE VOC√ä OFERECE:
                {product_service_offered}

                INSTRU√á√ïES:
                Com base nas informa√ß√µes fornecidas:
                1.  Identifique a categoria principal dos pontos de dor.
                2.  Liste de 2 a 3 pontos de dor detalhados que a persona provavelmente enfrenta, considerando o contexto da empresa '{company_name}' e a an√°lise do lead. Para cada um:
                    a.  Descreva a dor espec√≠fica.
                    b.  Explique o impacto de neg√≥cio dessa dor (opera√ß√µes, receita, etc.).
                    c.  Indique como o {product_service_offered} se alinha para resolver essa dor.
                3.  Avalie o n√≠vel de urg√™ncia geral para resolver esses pontos de dor (low, medium, high, critical).
                4.  Formule de 2 a 4 perguntas investigativas abertas e espec√≠ficas para aprofundar a compreens√£o dos problemas e suas implica√ß√µes.
                
                Retorne APENAS um objeto JSON com a seguinte estrutura:
                {{
                    "primary_pain_category": "Categoria principal dos pontos de dor (string)",
                    "detailed_pain_points": [
                        {{
                            "pain_description": "Descri√ß√£o espec√≠fica da dor (string)",
                            "business_impact": "Como isso impacta opera√ß√µes/receita (string)",
                            "solution_alignment": "Como nossa solu√ß√£o {product_service_offered} aborda essa dor (string)"
                        }}
                    ],
                    "urgency_level": "low|medium|high|critical (string)",
                    "investigative_questions": ["Pergunta investigativa 1 (string)", "Pergunta investigativa 2 (string)"]
                }}
                N√£o inclua explica√ß√µes adicionais fora do JSON.
            """

            formatted_prompt = prompt_template.format(
                lead_analysis=truncated_analysis,
                persona_profile=truncated_persona,
                product_service_offered=input_data.product_service_offered,
                company_name=input_data.company_name
            )

            self.logger.debug("ü§ñ Generating LLM response for pain point analysis")
            llm_response_str = self.generate_llm_response(formatted_prompt)

            if not llm_response_str:
                self.logger.error("‚ùå LLM call returned no response for pain point deepening")
                return PainPointDeepeningOutput(error_message="LLM call returned no response.")

            self.logger.debug(f"‚úÖ LLM returned response, length: {len(llm_response_str)}")
            
            parsed_output = self.parse_llm_json_response(llm_response_str, PainPointDeepeningOutput)
            
            # If parsing failed, parse_llm_json_response might set parsed_output.error_message
            if parsed_output.error_message:
                self.logger.warning(f"‚ö†Ô∏è  PainPointDeepeningAgent JSON parsing failed. Raw response: {llm_response_str[:500]}")
                self.logger.warning("‚ùå No regex fallback available for complex pain point structure")
            else:
                # Log successful parsing details
                pain_points_count = len(parsed_output.detailed_pain_points)
                questions_count = len(parsed_output.investigative_questions)
                self.logger.info(f"‚úÖ Pain point analysis successful: category={parsed_output.primary_pain_category}, points={pain_points_count}, urgency={parsed_output.urgency_level}, questions={questions_count}")

            return parsed_output

        except Exception as e:
            self.logger.error(f"An unexpected error occurred in {self.name}: {e}")
            import traceback
            traceback.print_exc()
            return PainPointDeepeningOutput(error_message=f"An unexpected error occurred: {str(e)}")

if __name__ == '__main__':
    class MockLLMClient(LLMClientBase):
        def __init__(self, api_key: str = "mock_key"):
            super().__init__(api_key)

        def generate_text_response(self, prompt: str) -> Optional[str]:
            if "PONTOS DE DOR APROFUNDADOS E PERGUNTAS INVESTIGATIVAS" in prompt:
                return (
                    "Para a Empresa Exemplo:\n\n"
                    "Ponto de Dor 1: Otimiza√ß√£o de Processos Manuais Identificada na An√°lise.\n"
                    "   - Pergunta Investigativa: Carlos, voc√™ mencionou a busca por efici√™ncia. Poderia descrever como os processos manuais atuais impactam o tempo de resposta da sua equipe?\n"
                    "   - Pergunta Investigativa: Quais s√£o os custos (diretos e indiretos) que voc√™ associa √† manuten√ß√£o desses processos manuais?\n"
                    "   - Observa√ß√£o: Solu√ß√µes como Nossas Solu√ß√µes Incr√≠veis frequentemente ajudam a automatizar tais processos, liberando tempo da equipe para tarefas mais estrat√©gicas.\n\n"
                    "Ponto de Dor 2: Integra√ß√£o de Novas Tecnologias (mencionado no perfil da persona).\n"
                    "   - Pergunta Investigativa: Ao considerar novas tecnologias, quais s√£o suas maiores preocupa√ß√µes em termos de integra√ß√£o com os sistemas existentes na Empresa Exemplo?\n"
                    "   - Pergunta Investigativa: Como a equipe normalmente lida com a curva de aprendizado de novas ferramentas?\n"
                    "   - Observa√ß√£o: A facilidade de integra√ß√£o e o suporte robusto s√£o aspectos que Nossas Solu√ß√µes Incr√≠veis priorizam para mitigar esses desafios."
                )
            return "Resposta padr√£o do mock."

    print("Running mock test for PainPointDeepeningAgent...")
    mock_llm = MockLLMClient()
    agent = PainPointDeepeningAgent(llm_client=mock_llm)

    test_lead_analysis = "A Empresa Exemplo (m√©dio porte, setor de TI) enfrenta desafios na otimiza√ß√£o de processos internos, muitos ainda manuais."
    test_persona_profile = (
        "Carlos Mendes, Diretor de Opera√ß√µes da Empresa Exemplo. Respons√°vel por efici√™ncia e implementa√ß√£o de novas tecnologias. "
        "Busca ROI claro e integra√ß√£o f√°cil. Comunica√ß√£o direta."
    )
    test_product_service = "Nossas Solu√ß√µes Incr√≠veis"
    test_company_name = "Empresa Exemplo"

    input_data = PainPointDeepeningInput(
        lead_analysis=test_lead_analysis,
        persona_profile=test_persona_profile,
        product_service_offered=test_product_service,
        company_name=test_company_name
    )

    output = agent.process(input_data)

    print(f"Deepened Pain Points: {output.deepened_pain_points}")
    if output.error_message:
        print(f"Error: {output.error_message}")

    assert "Empresa Exemplo" in output.deepened_pain_points
    assert "Carlos" in output.deepened_pain_points # Check if persona context was used
    assert "Nossas Solu√ß√µes Incr√≠veis" in output.deepened_pain_points
    assert "Pergunta Investigativa:" in output.deepened_pain_points
    assert output.error_message is None
    print("Mock test completed.")
