# Nellia Prospector - Intelligent Lead Processing System

## 1. Overview

**Project Goal:** To develop a sophisticated multi-agent system, "Nellia Prospector," that processes potential leads provided by an external "Harvester" service. This system will analyze each lead, create personas, develop tailored approach plans, and craft personalized messages for initial outreach. The ultimate aim is to transform raw lead data into actionable, high-quality engagement opportunities.

**Core Input:** The system will ingest a structured JSON file generated by the Harvester, containing a list of websites and associated extracted data.

## 2. High-Level Architecture

Nellia Prospector will be architected as a pipeline of specialized, autonomous (or semi-autonomous) agents. Each agent will be responsible for a specific stage of lead processing. The output of one agent will serve as the structured input for the next, ensuring a clear flow of enriched data.

The initial focus is to decompose the existing monolithic lead processing logic into the following distinct agents:

* **Lead Intake & Validation Agent** (Optional but Recommended)
* **Lead Analysis Agent**
* **Persona Creation Agent**
* **Approach Strategy Agent**
* **Personalized Message Crafting Agent**

Future agents (e.g., for automated outreach, follow-up, CRM logging) can be added to this pipeline later.

## 3. Input Data Structure (from Harvester)

The system expects a JSON input file from the Harvester. This file contains an array of `sites_data`, where each object represents a potential lead with its URL, Google search context, and extracted text content (if successful).

**Example JSON Structure:**

```json
{
  "original_query": "escritórios de advocacia em curitiba",
  "collection_timestamp": "2025-05-29T14:52:45.581542",
  "total_sites_targeted_for_processing": 48,
  "total_sites_processed_in_extraction_phase": 48,
  "sites_data": [
    {
      "url": "[https://romano.adv.br/](https://romano.adv.br/)",
      "Google Search_data": {
        "title": "Romano Advogados – Escritório de Advocacia Empresarial ...",
        "snippet": "Romano Advogados https:// · Translate this page"
      },
      "extracted_text_content": "FALHA NA EXTRAÇÃO: TIMEOUT NA NAVEGAÇÃO.",
      "extraction_status_message": "FALHA NA EXTRAÇÃO: TIMEOUT NA NAVEGAÇÃO.",
      "screenshot_filepath": null
    },
    {
      "url": "[https://araujolisot.com.br/](https://araujolisot.com.br/)",
      "Google Search_data": {
        "title": "Araujo & Lisot Advogados: Escritório de advocacia em ...",
        "snippet": "https:// · Translate this page"
      },
      "extracted_text_content": "Lorem Ipsum 3\\n22 de março de 2021\\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut\\nLorem Ipsum 2\\n22 de março de 2021\\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut\\nLorem Ipsum\\n22 de março de 2021\\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut",
      "extraction_status_message": "SUCESSO NA EXTRAÇÃO",
      "screenshot_filepath": "screenshot_extract_araujolisotcombr__142812.png"
    }
   ]
}
```

The primary focus for processing will be individual entries within the `sites_data` array, particularly those with `"extraction_status_message": "SUCESSO NA EXTRAÇÃO"`.

## 4. Core Agent Definitions and Responsibilities

Each agent will handle one specific `site_data` object at a time, or a batch of them, enriching it with its specific analysis and passing it on.

### 4.1. Lead Intake & Validation Agent (Optional First Pass)

* **Input:** A single `site_data` object from the Harvester's JSON.
* **Responsibilities:**
    * Validate the structure of the input.
    * Filter out leads with critical extraction failures (e.g., based on `extraction_status_message`).
    * Perform any initial data cleaning or normalization if necessary.
    * Log skipped/invalid leads.
* **Output:** A validated and cleaned `lead_data` object (similar to `site_data` but potentially with added validation flags or minor transformations). If this agent is skipped, the Lead Analysis Agent takes raw `site_data`.

### 4.2. Lead Analysis Agent

* **Input:** A validated `lead_data` object (or a raw `site_data` object if the Intake Agent is not implemented).
* **Responsibilities:**
    * Perform in-depth analysis of the `extracted_text_content`.
    * Use LLMs or other NLP techniques to understand the company's business, services, target audience, and potential pain points.
    * Corroborate findings with `Google Search_data` (title, snippet).
    * Identify key information such as company focus, specialization, and any explicit needs or problems mentioned.
    * Determine the relevance of the lead to Nellia's products/services (or its client's products/services).
* **Output:** An `analyzed_lead` object/dictionary containing the original lead data plus new fields like:
    * `company_summary`
    * `identified_services_offered`
    * `potential_pain_points`
    * `relevance_score` (e.g., to Nellia Prospector's target client profile)
    * `key_information_points` (list of strings)

### 4.3. Persona Creation Agent

* **Input:** An `analyzed_lead` object from the Lead Analysis Agent.
* **Responsibilities:**
    * Based on the `analyzed_lead` data (company summary, services, pain points), create a detailed persona for the ideal contact person within that company or for the company as a whole (if B2B context demands it).
    * The persona should include characteristics like:
        * Likely role/job title of the decision-maker.
        * Their primary goals and motivations.
        * Their key challenges (related to the `potential_pain_points`).
        * Preferred communication style (inferred, e.g., formal, direct).
* **Output:** A `lead_with_persona` object, containing all previous data plus:
    * `persona_details`: (e.g., a dictionary or a structured string with role, goals, challenges, communication_style).

### 4.4. Approach Strategy Agent

* **Input:** A `lead_with_persona` object from the Persona Creation Agent.
* **Responsibilities:**
    * Develop a tailored approach strategy for this specific lead.
    * Identify unique selling propositions (USPs) of Nellia's (or its client's) offering that align with the lead's `potential_pain_points` and `persona_details.challenges`.
    * Outline key talking points or value propositions for the initial outreach.
    * Suggest the primary objective of the first interaction (e.g., schedule a call, offer a resource, build rapport).
* **Output:** A `lead_with_strategy` object, containing all previous data plus:
    * `approach_plan`: (e.g., a dictionary with `key_talking_points`, `value_proposition_angles`, `first_interaction_objective`).

### 4.5. Personalized Message Crafting Agent

* **Input:** A `lead_with_strategy` object from the Approach Strategy Agent.
* **Responsibilities:**
    * Generate a personalized outreach message (e.g., email draft, LinkedIn icebreaker draft).
    * The message should incorporate:
        * Information from `analyzed_lead` (e.g., reference their specific business/service).
        * Insights from `persona_details` (e.g., address their likely goals/challenges, adapt to communication style).
        * Elements from the `approach_plan` (key talking points, value propositions).
    * Ensure the message is concise, engaging, and has a clear call to action aligned with `first_interaction_objective`.
* **Output:** A `final_prospect_package` object, containing all previous data plus:
    * `personalized_message_draft`: (string containing the message)
    * `suggested_subject_line` (if applicable for email)

## 5. Proposed Code Structure

A modular structure is recommended to keep agents and their functionalities organized.

```
nellia_prospector_system/
├── main.py                     # Orchestrator script to run the agent pipeline
├── harvester.py                # This is the initial harvester prototype, used to generate the harvester_outputs. We are not automatically running it for now. Only manually
├── harvester_output_examples/  # Store example JSON and PNG files from the harvester
│   └── example_leads.json
├── agents/
│   ├── __init__.py
│   ├── base_agent.py           # Optional: Abstract base class for agents
│   ├── lead_intake_agent.py    # Or lead_validator_agent.py
│   ├── lead_analysis_agent.py
│   ├── persona_creation_agent.py
│   ├── approach_strategy_agent.py
│   └── message_crafting_agent.py
├── core_logic/                 # For shared business logic, NLP utilities, LLM interaction clients
│   ├── __init__.py
│   ├── nlp_utils.py
│   └── llm_client.py
├── data_models/                # Pydantic models or dataclasses for structured data passed between agents
│   ├── __init__.py
│   └── lead_structures.py
└── utils/                      # General utility functions (e.g., file I/O, logging)
    ├── __init__.py
    └── file_handler.py
    └── logger_config.py
```

## 6. Data Flow and Inter-Agent Communication

1.  The `main.py` orchestrator will read the Harvester's JSON file.
2.  It will iterate through each `site_data` entry (or a batch).
3.  For each entry, it will pass the data object sequentially through the defined agents:
    * `LeadIntakeAgent` output -> `LeadAnalysisAgent` input
    * `LeadAnalysisAgent` output -> `PersonaCreationAgent` input
    * `PersonaCreationAgent` output -> `ApproachStrategyAgent` input
    * `ApproachStrategyAgent` output -> `PersonalizedMessageCraftingAgent` input
4.  Each agent enriches the data object and passes the augmented version to the next.
5.  The final output for each processed lead will be the `final_prospect_package` containing all accumulated data and the personalized message. This can then be stored, displayed, or passed to a subsequent outreach system.

Using well-defined data structures (e.g., Python dictionaries or dedicated classes/Pydantic models defined in `data_models/`) is crucial for clean inter-agent data exchange.

## 7. Development Guidelines

* **Modularity:** Each agent should be a distinct module/class with a clear responsibility.
* **Clear Interfaces:** Define how each agent receives input and produces output.
* **Reusability:** Common functionalities (like LLM calls, specific NLP tasks) should be placed in `core_logic/` to be reused by multiple agents if needed.
* **Testability:** Design agents so they can be tested individually.
* **Configuration:** Allow for easy configuration (e.g., LLM model names, API keys, prompts) possibly through a separate config file or environment variables.
* **Logging:** Implement comprehensive logging throughout the pipeline to track the processing of each lead and any errors.
* **Error Handling:** Each agent should gracefully handle potential errors during its processing (e.g., LLM API errors, unexpected data format).

## 8. Google's Agent2Agent (A2A) Protocol - Potential Integration

Google's Agent2Agent (A2A) Protocol (https://github.com/google-a2a/A2A) is an open standard designed to enable communication and interoperability between AI agents built on different frameworks. A2A provides a common language for agents to discover each other, negotiate capabilities, and collaborate on tasks while maintaining their internal opacity.

### What is A2A?

A2A is an open protocol that addresses the challenge of enabling AI agents from different ecosystems to communicate effectively. Key features include:

* **Standardized Communication:** JSON-RPC 2.0 over HTTP(S)
* **Agent Discovery:** Via "Agent Cards" detailing capabilities and connection info
* **Flexible Interaction:** Supports synchronous request/response, streaming (SSE), and asynchronous push notifications
* **Rich Data Exchange:** Handles text, files, and structured JSON data
* **Preserves Agent Opacity:** Agents can collaborate without exposing internal state, memory, or tools

### Potential A2A Integration in Nellia Prospector

While the current implementation uses direct function calls between agents, integrating Google's A2A Protocol could provide several benefits:

1. **Distributed Architecture:** Each agent could run as a separate service, potentially on different servers
2. **Language Agnostic:** Agents could be implemented in different programming languages
3. **Scalability:** Individual agents could be scaled independently based on load
4. **Interoperability:** Could integrate with other A2A-compliant agents from different vendors
5. **Flexibility:** Could easily swap out agent implementations without changing the overall pipeline

### Proposed A2A Architecture for Nellia Prospector

If implementing A2A, each agent would:
- Expose an A2A-compliant endpoint
- Publish an Agent Card describing its capabilities
- Accept and process lead data via standardized A2A messages
- Return enriched lead data in A2A format

Example flow:
1. Lead Intake Agent receives harvester data, validates it, and sends to Analysis Agent via A2A
2. Analysis Agent processes the lead and sends analyzed data to Persona Agent via A2A
3. This continues through the pipeline with each agent discovering and communicating via A2A

### Implementation Considerations

- Install the A2A SDK: `pip install a2a-sdk`
- Create A2A server endpoints for each agent
- Define Agent Cards for capability discovery
- Implement A2A message handlers
- Set up service discovery mechanism

Note: The current implementation does not use A2A, but the modular agent architecture makes it straightforward to add A2A support in the future.
